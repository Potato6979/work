import pandas as pd
import numpy as np
import warnings
import os
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from src.data_preprocessing import DataPreprocessor, EDAAnalyzer
from src.model_training import ModelTrainer
from src.model_evaluation import ModelEvaluator
from src.visualization import VisualizationTools

warnings.filterwarnings('ignore')

class HeartDiseaseMLProject:
    def __init__(self, data_path='data/heart.csv', random_state=42):
        self.data_path = data_path
        self.random_state = random_state
        self.preprocessor = DataPreprocessor()
        self.eda_analyzer = EDAAnalyzer()
        self.trainer = ModelTrainer(random_state=random_state)
        self.evaluator = ModelEvaluator()
        self.visualizer = VisualizationTools()
        
        # æ•°æ®å­˜å‚¨
        self.raw_data = None
        self.processed_data = None
        self.X_train = None
        self.X_val = None
        self.X_test = None
        self.y_train = None
        self.y_val = None
        self.y_test = None
        self.results = None
        
        print("=== å¿ƒè„ç—…é¢„æµ‹æœºå™¨å­¦ä¹ é¡¹ç›® ===")
        print(f"é¡¹ç›®åˆå§‹åŒ–å®Œæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def load_and_explore_data(self):
        """æ•°æ®åŠ è½½å’Œæ¢ç´¢æ€§åˆ†æ"""
        print("\n" + "="*50)
        print("ç¬¬ä¸€æ­¥: æ•°æ®åŠ è½½å’Œæ¢ç´¢æ€§åˆ†æ")
        print("="*50)
        
        # åŠ è½½æ•°æ®
        self.raw_data = self.preprocessor.load_data(self.data_path)
        
        # åŸºæœ¬ä¿¡æ¯
        basic_stats = self.preprocessor.basic_info(self.raw_data)
        
        # æ¢ç´¢æ€§æ•°æ®åˆ†æ
        print("\nè¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æ...")
        self.eda_analyzer.plot_target_distribution(self.raw_data)
        self.eda_analyzer.plot_feature_distributions(self.raw_data)
        self.eda_analyzer.plot_correlation_matrix(self.raw_data)
        
        # ç»Ÿè®¡æ‘˜è¦
        self.eda_analyzer.statistical_summary(self.raw_data)
        
        # æ•°æ®æ¦‚è§ˆå›¾
        self.visualizer.plot_data_overview(self.raw_data)
        
        return basic_stats
    
    def preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        print("\n" + "="*50)
        print("ç¬¬äºŒæ­¥: æ•°æ®é¢„å¤„ç†")
        print("="*50)
        
        # å¤„ç†ç¼ºå¤±å€¼
        self.processed_data = self.preprocessor.handle_missing_values(self.raw_data.copy())
        
        # å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
        self.processed_data = self.preprocessor.detect_outliers(self.processed_data)
        
        # ç‰¹å¾å·¥ç¨‹
        self.processed_data = self.preprocessor.feature_engineering(self.processed_data)
        
        # ç±»åˆ«å˜é‡ç¼–ç 
        self.processed_data = self.preprocessor.encode_categorical(self.processed_data)
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        X = self.processed_data.drop('target', axis=1)
        y = self.processed_data['target']
        
        # æ•°æ®åˆ†å‰²
        self.X_train, self.X_val, self.X_test, self.y_train, self.y_val, self.y_test = \
            self.preprocessor.split_data(X, y, test_size=0.2, val_size=0.25)
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        self.X_train, self.X_val, self.X_test = \
            self.preprocessor.normalize_features(self.X_train, self.X_val, self.X_test)
        
        print(f"é¢„å¤„ç†å®Œæˆ!")
        print(f"æœ€ç»ˆç‰¹å¾æ•°é‡: {self.X_train.shape[1]}")
        print(f"è®­ç»ƒé›†å¤§å°: {self.X_train.shape[0]}")
        print(f"éªŒè¯é›†å¤§å°: {self.X_val.shape[0]}")
        print(f"æµ‹è¯•é›†å¤§å°: {self.X_test.shape[0]}")
    
    def train_models(self, tune_hyperparams=True):
        """æ¨¡å‹è®­ç»ƒ"""
        print("\n" + "="*50)
        print("ç¬¬ä¸‰æ­¥: æ¨¡å‹è®­ç»ƒ")
        print("="*50)
        
        # è®­ç»ƒæ‰€æœ‰åŸºç¡€æ¨¡å‹
        self.trainer.train_all_models(self.X_train, self.y_train, tune_hyperparams)
        
        # åˆ›å»ºé›†æˆæ¨¡å‹
        self.trainer.create_ensemble_models(self.X_train, self.y_train)
        
        print(f"\nè®­ç»ƒå®Œæˆ! å…±è®­ç»ƒäº† {len(self.trainer.trained_models)} ä¸ªæ¨¡å‹")
        
        # ç»˜åˆ¶å­¦ä¹ æ›²çº¿ï¼ˆé€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ¨¡å‹ï¼‰
        representative_models = ['logistic', 'random_forest', 'xgboost']
        for model_name in representative_models:
            if model_name in self.trainer.trained_models:
                print(f"\nç»˜åˆ¶ {model_name} å­¦ä¹ æ›²çº¿...")
                self.trainer.plot_learning_curves(model_name, self.X_train, self.y_train)
    
    def evaluate_models(self):
        """æ¨¡å‹è¯„ä¼°"""
        print("\n" + "="*50)
        print("ç¬¬å››æ­¥: æ¨¡å‹è¯„ä¼°")
        print("="*50)
        
        # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
        self.results = self.evaluator.evaluate_all_models(
            self.trainer.trained_models, self.X_test, self.y_test
        )
        
        # ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾
        self.visualizer.plot_model_performance_comparison(self.results)
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        self.evaluator.plot_confusion_matrices(self.y_test)
        
        # ç»˜åˆ¶ROCæ›²çº¿
        self.evaluator.plot_roc_curves(self.y_test)
        
        # ç»˜åˆ¶PRæ›²çº¿
        self.evaluator.plot_precision_recall_curves(self.y_test)
        
        # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå¯¹å‡ ä¸ªä¸»è¦æ¨¡å‹ï¼‰
        important_models = ['random_forest', 'xgboost', 'gradient_boosting']
        for model_name in important_models:
            if model_name in self.trainer.trained_models:
                print(f"\nåˆ†æ {model_name} ç‰¹å¾é‡è¦æ€§...")
                self.evaluator.feature_importance_analysis(
                    self.trainer.trained_models[model_name], 
                    model_name, 
                    self.X_test, 
                    self.y_test, 
                    self.X_train.columns.tolist()
                )
        
        # SHAPåˆ†æï¼ˆé€‰æ‹©æœ€ä½³æ¨¡å‹ï¼‰
        best_model_name = self.results.iloc[0]['model']
        if best_model_name in self.trainer.trained_models:
            print(f"\nå¯¹æœ€ä½³æ¨¡å‹ {best_model_name} è¿›è¡ŒSHAPåˆ†æ...")
            self.evaluator.shap_analysis(
                self.trainer.trained_models[best_model_name],
                self.X_test,
                self.X_train.columns.tolist(),
                best_model_name
            )
        
        # é”™è¯¯åˆ†æ
        self.evaluator.error_analysis(
            self.y_test, self.X_test, self.X_train.columns.tolist()
        )
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.evaluator.generate_classification_report(self.y_test)
        
        return self.results
    
    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        print("\n" + "="*50)
        print("ç¬¬äº”æ­¥: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        print("="*50)
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_info = self.results.iloc[0]
        
        print(f"\n=== é¡¹ç›®æ€»ç»“æŠ¥å‘Š ===")
        print(f"æ•°æ®é›†è§„æ¨¡: {len(self.raw_data)} ä¸ªæ ·æœ¬")
        print(f"ç‰¹å¾æ•°é‡: {self.X_train.shape[1]} ä¸ª")
        print(f"è®­ç»ƒæ¨¡å‹æ•°é‡: {len(self.trainer.trained_models)} ä¸ª")
        
        print(f"\n=== æœ€ä½³æ¨¡å‹æ€§èƒ½ ===")
        print(f"æœ€ä½³æ¨¡å‹: {best_model_info['model']}")
        print(f"å‡†ç¡®ç‡: {best_model_info['accuracy']:.4f}")
        print(f"ç²¾ç¡®ç‡: {best_model_info['precision']:.4f}")  
        print(f"å¬å›ç‡: {best_model_info['recall']:.4f}")
        print(f"F1åˆ†æ•°: {best_model_info['f1']:.4f}")
        if 'auc_roc' in best_model_info:
            print(f"AUC-ROC: {best_model_info['auc_roc']:.4f}")
        
        print(f"\n=== æ€§èƒ½æ’å ===")
        for i, row in self.results.head().iterrows():
            print(f"{i+1}. {row['model']}: {row['accuracy']:.4f}")
        
        # æ¨¡å‹æ¯”è¾ƒå¯è§†åŒ–
        self.evaluator.model_comparison_plot()
        
        print(f"\né¡¹ç›®å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    def save_results(self, output_dir='./output'):
        """ä¿å­˜ç»“æœ"""
        print("\n" + "="*50)
        print("ä¿å­˜ç»“æœ")
        print("="*50)
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        model_path = os.path.join(output_dir, 'trained_models.pkl')
        self.trainer.save_models(model_path)
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results_path = os.path.join(output_dir, 'evaluation_results.pkl')
        self.evaluator.save_results(results_path)
        
        # ä¿å­˜é¢„å¤„ç†å™¨
        import joblib
        preprocessor_path = os.path.join(output_dir, 'preprocessor.pkl')
        joblib.dump(self.preprocessor, preprocessor_path)
        
        # ä¿å­˜ç»“æœCSV
        csv_path = os.path.join(output_dir, 'model_results.csv')
        self.results.to_csv(csv_path, index=False)
        
        print(f"æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    def run_complete_pipeline(self, save_results=True):
        """è¿è¡Œå®Œæ•´çš„æœºå™¨å­¦ä¹ æµç¨‹"""
        try:
            # 1. æ•°æ®åŠ è½½å’Œæ¢ç´¢
            self.load_and_explore_data()
            
            # 2. æ•°æ®é¢„å¤„ç†
            self.preprocess_data()
            
            # 3. æ¨¡å‹è®­ç»ƒ
            self.train_models(tune_hyperparams=True)
            
            # 4. æ¨¡å‹è¯„ä¼°
            self.evaluate_models()
            
            # 5. ç”ŸæˆæŠ¥å‘Š
            self.generate_final_report()
            
            # 6. ä¿å­˜ç»“æœ
            if save_results:
                self.save_results()
            
            print("\nğŸ‰ é¡¹ç›®æ‰§è¡Œå®Œæˆ!")
            
        except Exception as e:
            print(f"\nâŒ é¡¹ç›®æ‰§è¡Œå‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    data_path = 'data/heart.csv'
    if not os.path.exists(data_path):
        print(f"æ•°æ®æ–‡ä»¶ {data_path} ä¸å­˜åœ¨!")
        print("è¯·ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½æ•°æ®:")
        print("https://archive.ics.uci.edu/ml/datasets/heart+disease")
        return
    
    # åˆ›å»ºé¡¹ç›®å®ä¾‹
    project = HeartDiseaseMLProject(data_path=data_path, random_state=42)
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    project.run_complete_pipeline(save_results=True)
    
    # åˆ›å»ºäº¤äº’å¼ä»ªè¡¨æ¿ï¼ˆå¯é€‰ï¼‰
    try:
        project.visualizer.create_interactive_dashboard(
            project.processed_data, project.results
        )
    except Exception as e:
        print(f"äº¤äº’å¼ä»ªè¡¨æ¿åˆ›å»ºå¤±è´¥: {e}")

if __name__ == "__main__":
    main()